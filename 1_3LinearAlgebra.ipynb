{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.3LinearAlgebra.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNh9dQ6lumlfV6AsytEjWSF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaacd68/MAT494-data-science/blob/main/1_3LinearAlgebra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5n8nXJfXlVi"
      },
      "source": [
        "***QR Decompostion***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR-dmSRhYDTW"
      },
      "source": [
        "To calculate the QR Decomposition of a matrix  with NumPy/SciPy, we can make use of the built-in linalg library via the linalg.qr function. This is significantly more efficient than using a pure Python implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8HjcA4_XGg1",
        "outputId": "4dfaebf0-c6b8-4318-d718-8a64a0d7750e"
      },
      "source": [
        "import pprint\n",
        "import numpy as np\n",
        "import scipy.linalg   # SciPy Linear Algebra Library\n",
        "\n",
        "A = np.array([[12, -51, 4], [6, 167, -68], [-4, 24, -41]])  \n",
        "Q, R = scipy.linalg.qr(A)\n",
        "\n",
        "print (\"A:\")\n",
        "pprint.pprint(A)\n",
        "\n",
        "print (\"Q:\")\n",
        "pprint.pprint(Q)\n",
        "\n",
        "print (\"R:\")\n",
        "pprint.pprint(R)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A:\n",
            "array([[ 12, -51,   4],\n",
            "       [  6, 167, -68],\n",
            "       [ -4,  24, -41]])\n",
            "Q:\n",
            "array([[-0.85714286,  0.39428571,  0.33142857],\n",
            "       [-0.42857143, -0.90285714, -0.03428571],\n",
            "       [ 0.28571429, -0.17142857,  0.94285714]])\n",
            "R:\n",
            "array([[ -14.,  -21.,   14.],\n",
            "       [   0., -175.,   70.],\n",
            "       [   0.,    0.,  -35.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feoF3r91ZG4a"
      },
      "source": [
        "The output of $R$ is a check to make sure it is an upper triangular matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTFA1QGuZUNA"
      },
      "source": [
        "Using the Householder Reflections algorithim to have a better idea for QR decomposition in python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "-BUmK2bIYqGq",
        "outputId": "12de7dd3-d79a-4bba-ecbd-ba3713f3a8ab"
      },
      "source": [
        "from math import sqrt\n",
        "from pprint import pprint\n",
        "import math\n",
        "import numpy as np\n",
        "import scipy.linalg\n",
        "\n",
        "A = np.array([[12, -51, 4], [6, 167, -68], [-4, 24, -41]])  \n",
        "Q, R = scipy.linalg.qr(A)\n",
        "\n",
        "print (\"A:\")\n",
        "pprint(A)\n",
        "\n",
        "print (\"Q:\")\n",
        "pprint(Q)\n",
        "\n",
        "print (\"R:\")\n",
        "pprint(R) \n",
        "\n",
        "def mult_matrix(M, N):\n",
        "    \"\"\"Multiply square matrices of same dimension M and N\"\"\"\n",
        "    # Converts N into a list of tuples of columns                                                                     \n",
        "    tuple_N = zip(*N)\n",
        "\n",
        "    # Nested list comprehension to calculate matrix multiplication                                                    \n",
        "    return [[sum(el_m * el_n for el_m, el_n in zip(row_m, col_n)) for col_n in tuple_N] for row_m in M]\n",
        "\n",
        "def trans_matrix(M):\n",
        "    \"\"\"Take the transpose of a matrix.\"\"\"\n",
        "    n = len(M)\n",
        "    return [[ M[i][j] for i in range(n)] for j in range(n)]\n",
        "\n",
        "def norm(x):\n",
        "    \"\"\"Return the Euclidean norm of the vector x.\"\"\"\n",
        "    return sqrt(sum([x_i**2 for x_i in x]))\n",
        "\n",
        "def Q_i(Q_min, i, j, k):\n",
        "    \"\"\"Construct the Q_t matrix by left-top padding the matrix Q                                                      \n",
        "    with elements from the identity matrix.\"\"\"\n",
        "    if i < k or j < k:\n",
        "        return float(i == j)\n",
        "    else:\n",
        "        return Q_min[i-k][j-k]\n",
        "\n",
        "def householder(A):\n",
        "    \"\"\"Performs a Householder Reflections based QR Decomposition of the                                               \n",
        "    matrix A. The function returns Q, an orthogonal matrix and R, an                                                  \n",
        "    upper triangular matrix such that A = QR.\"\"\"\n",
        "    n = len(A)\n",
        "\n",
        "    # Set R equal to A, and create Q as a zero matrix of the same size\n",
        "    R = A\n",
        "    Q = [[0.0] * n for i in range(n)]\n",
        "\n",
        "    # The Householder procedure\n",
        "    for k in range(n-1):  # We don't perform the procedure on a 1x1 matrix, so we reduce the index by 1\n",
        "        # Create identity matrix of same size as A                                                                    \n",
        "        I = [[float(i == j) for i in range(n)] for j in range(n)]\n",
        "    \n",
        "        # Create the vectors x, e and the scalar alpha\n",
        "        ang = 0\n",
        "        x = [row[k] for row in R[k:]]\n",
        "        e = [row[k] for row in I[k:]]\n",
        "        alpha = -math.copysign(x[0], ang) * norm(x)\n",
        "\n",
        "        # Using anonymous functions, we create u and v\n",
        "        u = map(lambda p,q: p + alpha * q, x, e)\n",
        "        norm_u = norm(u)\n",
        "        v = map(lambda p: p/norm_u, u)\n",
        "\n",
        "        # Create the Q minor matrix\n",
        "        Q_min = [[float(i==j) - 2.0 * v[i] * v[j] for i in range(n-k)] for j in range(n-k)]\n",
        "        for i in range(n-k):\n",
        "              print(i)\n",
        "        for j in range(n-k):\n",
        "              print(j) \n",
        "        # \"Pad out\" the Q minor matrix with elements from the identity\n",
        "        Q_t = [[Q_i(Q_min,i,j,k) for i in range(n)] for j in range(n)]\n",
        "\n",
        "        # If this is the first run through, right multiply by A,\n",
        "        # else right multiply by Q\n",
        "        if k == 0:\n",
        "            Q = Q_t\n",
        "            R = mult_matrix(Q_t,A)\n",
        "        else:\n",
        "            Q = mult_matrix(Q_t,Q)\n",
        "            R = mult_matrix(Q_t,R)\n",
        "\n",
        "    # Since Q is defined as the product of transposes of Q_t,\n",
        "    # we need to take the transpose upon returning it\n",
        "    return trans_matrix(Q), R\n",
        "\n",
        "A = [[12, -51, 4], [6, 167, -68], [-4, 24, -41]]\n",
        "Q, R = householder(A)\n",
        "\n",
        "print (\"A:\")\n",
        "pprint(A)\n",
        "\n",
        "print (\"Q:\")\n",
        "pprint(Q)\n",
        "\n",
        "print (\"R:\")\n",
        "pprint(R)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A:\n",
            "array([[ 12, -51,   4],\n",
            "       [  6, 167, -68],\n",
            "       [ -4,  24, -41]])\n",
            "Q:\n",
            "array([[-0.85714286,  0.39428571,  0.33142857],\n",
            "       [-0.42857143, -0.90285714, -0.03428571],\n",
            "       [ 0.28571429, -0.17142857,  0.94285714]])\n",
            "R:\n",
            "array([[ -14.,  -21.,   14.],\n",
            "       [   0., -175.,   70.],\n",
            "       [   0.,    0.,  -35.]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-ca43287a1a49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m51\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m167\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m68\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhouseholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"A:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-ca43287a1a49>\u001b[0m in \u001b[0;36mhouseholder\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Create the Q minor matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mQ_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-ca43287a1a49>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Create the Q minor matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mQ_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-ca43287a1a49>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Create the Q minor matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mQ_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'map' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrBFIAylh4Yz"
      },
      "source": [
        "***Least Squares in python***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZvfvtKRiDq8"
      },
      "source": [
        "Generate data using the scikit-learn library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1yX-GjrKRZL"
      },
      "source": [
        "X, y, coefficients = make_regression(\n",
        "    n_samples=50,\n",
        "    n_features=1,\n",
        "    n_informative=1,\n",
        "    n_targets=1,\n",
        "    noise=5,\n",
        "    coef=True,\n",
        "    random_state=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvLPfrxiKzqU"
      },
      "source": [
        "Store the the rank and the number of columns of the matrix as variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8WmzFn9KTWC"
      },
      "source": [
        "n = X.shape[1]\n",
        "r = np.linalg.matrix_rank(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyh6kIY-K3Tq"
      },
      "source": [
        "Find the equivalent to our matrix of features using singular value decomposition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6aE0T2fJlwK"
      },
      "source": [
        "U, sigma, VT = np.linalg.svd(X, full_matrices=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMUxyEZoK5g1"
      },
      "source": [
        " $D^+$ can be derived from sigma"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-pDQHa0JoNB"
      },
      "source": [
        "D_plus = np.diag(np.hstack([1/sigma[:r], np.zeros(n-r)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQiDr-icLBsG"
      },
      "source": [
        "V is of course equal to the transpose of its transpose as described in the following identity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3rweYD1Jow1"
      },
      "source": [
        "V = VT.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dowMdyZrLEtZ"
      },
      "source": [
        "Determine Moore-Penrose pseudoinverse of X."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BOlITWWJr_B"
      },
      "source": [
        "X_plus = V.dot(D_plus).dot(U.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4_oq-UALJyI"
      },
      "source": [
        "The vector of coefficients can be calculated by multiplying the pseudoinverse of the matrix X by y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIW-TQAnJt-s"
      },
      "source": [
        "w = X_plus.dot(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feWEow6rLZjS"
      },
      "source": [
        "The actual error, we compute the residual sum of squares using the very first equation we saw."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToFKOU05Jz3D"
      },
      "source": [
        "error = np.linalg.norm(X.dot(w) - y, ord=2) ** 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_ND5H69LwUi"
      },
      "source": [
        "All together:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4irIj85JaXt",
        "outputId": "9a90ceee-8d6b-4d46-97e5-37f0cab1e989"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X, y, coefficients = make_regression(\n",
        "    n_samples=50,\n",
        "    n_features=1,\n",
        "    n_informative=1,\n",
        "    n_targets=1,\n",
        "    noise=5,\n",
        "    coef=True,\n",
        "    random_state=1\n",
        ")\n",
        "\n",
        "n = X.shape[1]\n",
        "r = np.linalg.matrix_rank(X)\n",
        "\n",
        "U, sigma, VT = np.linalg.svd(X, full_matrices=False)\n",
        "\n",
        "D_plus = np.diag(np.hstack([1/sigma[:r], np.zeros(n-r)]))\n",
        "\n",
        "V = VT.T\n",
        "\n",
        "X_plus = V.dot(D_plus).dot(U.T)\n",
        "\n",
        "w = X_plus.dot(y)\n",
        "\n",
        "error = np.linalg.norm(X.dot(w) - y, ord=2) ** 2\n",
        "print(error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "888.9637001387936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnA58wH9NM2t"
      },
      "source": [
        "***Linear Regression in Python***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdWiAt3sYL8m"
      },
      "source": [
        "The second step is defining data to work with. The inputs (regressors, ùë•) and output (predictor, ùë¶) should be arrays (the instances of the class numpy.ndarray) or similar objects. This is the simplest way of providing data for regression:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc379kcQYNXr"
      },
      "source": [
        "Now, you have two arrays: the input x and output y. You should call .reshape() on x because this array is required to be two-dimensional, or to be more precise, to have one column and as many rows as necessary. That‚Äôs exactly what the argument (-1, 1) of .reshape() specifies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27p2YmgMYRsl"
      },
      "source": [
        "As you can see, x has two dimensions, and x.shape is (6, 1), while y has a single dimension, and y.shape is (6,)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC4EZLTGYVtC"
      },
      "source": [
        "Let‚Äôs create an instance of the class LinearRegression, which will represent the regression mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If3EdqaqYgWp"
      },
      "source": [
        "This statement creates the variable model as the instance of LinearRegression. You can provide several optional parameters to LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MphwiLOYj1d"
      },
      "source": [
        "With .fit(), you calculate the optimal values of the weights ùëè‚ÇÄ and ùëè‚ÇÅ, using the existing input and output (x and y) as the arguments. In other words, .fit() fits the model. It returns self, which is the variable model itself. That‚Äôs why you can replace the last two statements with this one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIYTBZENYopA"
      },
      "source": [
        "Once you have your model fitted, you can get the results to check whether the model works satisfactorily and interpret it.\n",
        "\n",
        "You can obtain the coefficient of determination ($R^2$) with .score() called on model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Bg5WnhuYv41"
      },
      "source": [
        "When you‚Äôre applying .score(), the arguments are also the predictor x and regressor y, and the return value is $R^2$.\n",
        "\n",
        "The attributes of model are .intercept_, which represents the coefficient, $b_0$ and .coef_, which represents $b_1$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz3CIB68Y6fD"
      },
      "source": [
        "The code above illustrates how to get $b_0$ and $b_1$. You can notice that .intercept_ is a scalar, while .coef_ is an array.\n",
        "\n",
        "The value $b_0$ = 5.63 (approximately) illustrates that your model predicts the response 5.63 when $x$ is zero. The value $b_1$ = 0.54 means that the predicted response rises by 0.54 when $x$ is increased by one.\n",
        "\n",
        "You should notice that you can provide y as a two-dimensional array as well. In this case, you‚Äôll get a similar result. This is how it might look"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dOvbH4JZKhH"
      },
      "source": [
        "this example is very similar to the previous one, but in this case, .intercept_ is a one-dimensional array with the single element $b_0$, and .coef_ is a two-dimensional array with the single element $b_1$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v0K6INkZi8Y"
      },
      "source": [
        "To obtain the predicted response, use .predict()\n",
        "\n",
        "When applying .predict(), you pass the regressor as the argument and get the corresponding predicted response.\n",
        "\n",
        "This is a nearly identical way to predict the response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-j9hWYpZ9hP"
      },
      "source": [
        "In this case, you multiply each element of x with model.coef_ and add model.intercept_ to the product.\n",
        "\n",
        "The output here differs from the previous example only in dimensions. The predicted response is now a two-dimensional array, while in the previous case, it had one dimension.\n",
        "\n",
        "If you reduce the number of dimensions of x to one, these two approaches will yield the same result. You can do this by replacing x with x.reshape(-1), x.flatten(), or x.ravel() when multiplying it with model.coef_.\n",
        "\n",
        "In practice, regression models are often applied for forecasts. This means that you can use fitted models to calculate the outputs based on some other, new inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1zyvTI9NuGM",
        "outputId": "1726e804-8b66-453f-b2ff-905041169be8"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "x = np.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1))\n",
        "y = np.array([5, 20, 14, 32, 22, 38])\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "model.fit(x, y)\n",
        "\n",
        "model = LinearRegression().fit(x, y)\n",
        "\n",
        "r_sq = model.score(x, y)\n",
        "print('coefficient of determination:', r_sq)\n",
        "print('intercept:', model.intercept_)\n",
        "print('slope:', model.coef_)\n",
        "\n",
        "new_model = LinearRegression().fit(x, y.reshape((-1, 1)))\n",
        "print('intercept:', new_model.intercept_)\n",
        "print('slope:', new_model.coef_)\n",
        "\n",
        "y_pred = model.predict(x)\n",
        "print('predicted response:', y_pred, sep='\\n')\n",
        "\n",
        "y_pred = model.intercept_ + model.coef_ * x\n",
        "print('predicted response:', y_pred, sep='\\n')\n",
        "\n",
        "x_new = np.arange(5).reshape((-1, 1))\n",
        "print(x_new)\n",
        "y_new = model.predict(x_new)\n",
        "print(y_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 5]\n",
            " [15]\n",
            " [25]\n",
            " [35]\n",
            " [45]\n",
            " [55]]\n",
            "[ 5 20 14 32 22 38]\n",
            "coefficient of determination: 0.7158756137479542\n",
            "intercept: 5.633333333333329\n",
            "slope: [0.54]\n",
            "intercept: [5.63333333]\n",
            "slope: [[0.54]]\n",
            "predicted response:\n",
            "[ 8.33333333 13.73333333 19.13333333 24.53333333 29.93333333 35.33333333]\n",
            "predicted response:\n",
            "[[ 8.33333333]\n",
            " [13.73333333]\n",
            " [19.13333333]\n",
            " [24.53333333]\n",
            " [29.93333333]\n",
            " [35.33333333]]\n",
            "[[0]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [4]]\n",
            "[5.63333333 6.17333333 6.71333333 7.25333333 7.79333333]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}